{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "from scipy.io import wavfile\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import scipy.io.wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawNetDataset(Dataset):\n",
    "    def __init__(self, transform=None, mode=\"train\",files_dir=None, base_dir=\"\",csv_file_dir=\"\",nb_time=59049):\n",
    "        self.base_dir = base_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.csv_file_dir = csv_file_dir\n",
    "        self.files_dir = files_dir\n",
    "        csv_file = pd.read_csv(csv_file_dir,sep=\"\\t\")\n",
    "        self.nb_time = nb_time\n",
    "        self.classes = np.array([i for i, cls_name in enumerate(csv_file[\"VoxCeleb1 ID\"].unique())])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.classes.shape[0] \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.files_dir[idx]\n",
    "        X, sample_rate = torchaudio.load(self.base_dir+filename)\n",
    "        #print(\" shape(X): \",type(X))\n",
    "        label = self.classes[idx]\n",
    "        self._pre_emphasis(X)\n",
    "        nb_time = X.shape[1]\n",
    "        if nb_time > self.nb_time:\n",
    "            start_idx = np.random.randint(low = 0,\n",
    "                high = nb_time - self.nb_time)\n",
    "            X = X[:, start_idx:start_idx+self.nb_time]\n",
    "            #print(\"nb_time: \",nb_time )\n",
    "            #print(\"self.nb_time: \",self.nb_time)\n",
    "        elif nb_time < self.nb_time:\n",
    "            nb_dup = int(self.nb_time / nb_time) + 1\n",
    "            X = np.tile(X, (1, nb_dup))[:, :self.nb_time]\n",
    "            #print(\"taille inférieure\")\n",
    "        else:\n",
    "            X = X\n",
    "            #print(\"taille égale\")\n",
    "        print(\" type(X): \",X.size())\n",
    "\n",
    "        print('------------------------------------------------')\n",
    "\n",
    "        return X, label\n",
    "\n",
    "    def _pre_emphasis(self, x):\n",
    "        '''\n",
    "        Pre-emphasis for single channel input\n",
    "        '''\n",
    "        return np.asarray(x[:,1:] - 0.97 * x[:, :-1], dtype=np.float32) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/wav'\n",
    "list_IDs = ['/id10009/7hpSiT9_gCE/00001.wav',\n",
    "        '/id10009/aFttHpeaXaQ/00001.wav',\n",
    "        '/id10009/AtavJVP4bCk/00001.wav',\n",
    "        '/id10009/AtavJVP4bCk/00002.wav',\n",
    "        '/id10009/AtavJVP4bCk/00003.wav',\n",
    "        '/id10009/AtavJVP4bCk/00004.wav',\n",
    "        '/id10009/AtavJVP4bCk/00005.wav',\n",
    "        '/id10009/AtavJVP4bCk/00006.wav',\n",
    "        '/id10009/AtavJVP4bCk/00007.wav',\n",
    "        '/id10009/AtavJVP4bCk/00008.wav',\n",
    "        '/id10009/AtavJVP4bCk/00009.wav',\n",
    "        '/id10009/AtavJVP4bCk/00010.wav',\n",
    "        ]\n",
    "csv_file_dir = '../data/target/vox1_meta.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251\n"
     ]
    }
   ],
   "source": [
    "dataset = RawNetDataset(files_dir=list_IDs,base_dir=base_dir,csv_file_dir=csv_file_dir)\n",
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n",
      " type(X):  torch.Size([1, 59049])\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    dataset.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251,)\n"
     ]
    }
   ],
   "source": [
    "t=dataset.classes.shape[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "\n",
    "        # Non-linearity\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function  # LINEAR\n",
    "        out = self.fc1(x)\n",
    "\n",
    "        # Non-linearity  # NON-LINEAR\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        # Linear function (readout)  # LINEAR\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiation du model\n",
    "input_dim = 59049\n",
    "hidden_dim = 100\n",
    "output_dim = 1\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation de la loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x1c2e37b6d8>\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "print(model.parameters())\n",
    "print(len(list(model.parameters())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train model\n",
    "def train(num_epochs):\n",
    "    iter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Load images with gradient accumulation capabilities\n",
    "            images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get output/logits\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            iter += 1\n",
    "\n",
    "            if iter % 500 == 0:\n",
    "                # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Iterate through test dataset\n",
    "                for images, labels in test_loader:\n",
    "                    # Load images with gradient accumulation capabilities\n",
    "                    images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "                    # Forward pass only to get logits/output\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    # Total number of labels\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                    # Total correct predictions\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * correct / total\n",
    "\n",
    "                # Print Loss\n",
    "                print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
