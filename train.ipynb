{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "#import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "from scipy.io import wavfile\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawNetDataset(Dataset):\n",
    "    def __init__(self, transform=None, mode=\"train\",files_dir=None, base_dir=\"\",csv_file_dir=\"\",nb_time=59049):\n",
    "        self.base_dir = base_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.csv_file_dir = csv_file_dir\n",
    "        self.files_dir = files_dir\n",
    "        csv_file = pd.read_csv(csv_file_dir,sep=\"\\t\")\n",
    "        self.nb_time = nb_time\n",
    "        #self.classes = {cls_name:i+1 for i, cls_name in enumerate(csv_file[\"VoxCeleb1 ID\"].unique())}\n",
    "        self.classes = {'id10009': 0,'id10016': 1,'id10017': 2,'id10019': 3}\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.files_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.files_dir[idx]\n",
    "        classe = filename.split('/')[0]\n",
    "        X, sample_rate = torchaudio.load(self.base_dir + filename)\n",
    "        #print(\" shape(X): \",type(X))\n",
    "        label = self.classes[classe]\n",
    "        self._pre_emphasis(X)\n",
    "        nb_time = X.shape[1]\n",
    "        if nb_time > self.nb_time:\n",
    "            start_idx = np.random.randint(low = 0,\n",
    "                high = nb_time - self.nb_time)\n",
    "            X = X[:, start_idx:start_idx+self.nb_time]\n",
    "            #print(\"nb_time: \",nb_time )\n",
    "            #print(\"self.nb_time: \",self.nb_time)\n",
    "        elif nb_time < self.nb_time:\n",
    "            nb_dup = int(self.nb_time / nb_time) + 1\n",
    "            X = np.tile(X, (1, nb_dup))[:, :self.nb_time]\n",
    "            #print(\"taille inférieure\")\n",
    "        else:\n",
    "            X = X\n",
    "            #print(\"taille égale\")\n",
    "        #print(\" type(X): \",X.size())\n",
    "        return X, label\n",
    "\n",
    "    def _pre_emphasis(self, x):\n",
    "        '''\n",
    "        Pre-emphasis for single channel input\n",
    "        '''\n",
    "        return np.asarray(x[:,1:] - 0.97 * x[:, :-1], dtype=np.float32) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/wav/'\n",
    "csv_file_dir = 'data/target/vox1_meta.csv'\n",
    "def get_utt_list(src_dir):\n",
    "    l_utt = []\n",
    "    for r, ds, fs in os.walk(src_dir):\n",
    "        r = r.replace('\\\\', '/')   \n",
    "        base = '/'.join(r.split('/')[-2:])+'/'\n",
    "        for f in fs:\n",
    "            l_utt.append(base+f[:-4]+'.wav')\n",
    "    return l_utt\n",
    "list_IDs = get_utt_list(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_size = 59049       # input size\n",
    "hidden_size = 500      # The number of nodes at the hidden layer\n",
    "num_classes = 4      # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 5         # The number of times entire dataset is trained\n",
    "batch_size = 100       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN DATA\n",
    "train_dataset = RawNetDataset(files_dir=list_IDs,base_dir=base_dir,csv_file_dir=csv_file_dir)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset.__getitem__(0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST DATA\n",
    "test_dataset = RawNetDataset(files_dir=list_IDs,base_dir=base_dir,csv_file_dir=csv_file_dir)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        #print(out)\n",
    "        out = F.softmax(out, dim=0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "Epoch [1/5], Step [5/5], Loss: 1.3773\n",
      "data.shape torch.Size([42, 1, 59049])\n",
      "labels.size torch.Size([42])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "Epoch [2/5], Step [5/5], Loss: 1.3749\n",
      "data.shape torch.Size([42, 1, 59049])\n",
      "labels.size torch.Size([42])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "Epoch [3/5], Step [5/5], Loss: 1.3806\n",
      "data.shape torch.Size([42, 1, 59049])\n",
      "labels.size torch.Size([42])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "Epoch [4/5], Step [5/5], Loss: 1.3677\n",
      "data.shape torch.Size([42, 1, 59049])\n",
      "labels.size torch.Size([42])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "data.shape torch.Size([100, 1, 59049])\n",
      "labels.size torch.Size([100])\n",
      "Epoch [5/5], Step [5/5], Loss: 1.3790\n",
      "data.shape torch.Size([42, 1, 59049])\n",
      "labels.size torch.Size([42])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(train_loader):   # Load a batch of audio with its (index, data, class)\n",
    "        \n",
    "        #print('data.shape',data.shape)\n",
    "        #print('labels.size',labels.shape)\n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(data)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs.squeeze(), labels.long())                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % num_epochs == 0:                              # Logging\n",
    "            #print(loss.item())\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 1, 55])\n"
     ]
    }
   ],
   "source": [
    "sequence_length   = 75\n",
    "number_of_classes = 55\n",
    "# creates random tensor of your output shape\n",
    "output = torch.rand(sequence_length, 1, number_of_classes)\n",
    "# creates tensor with random targets\n",
    "target = torch.randint(55, (75,)).long()\n",
    "\n",
    "# define loss function and calculate loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# apply squeeze() on output tensor to change shape form [75, 1, 55] to [75, 55]\n",
    "loss = criterion(output.squeeze(), target)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of length 1:\n",
      "Output: tensor([[0.1582, 0.5060, 0.3160, 0.7548, 0.4619]]) shape: torch.Size([1, 5])\n",
      "Target: tensor([0]) shape: torch.Size([1])\n",
      "Loss: tensor(1.9107)\n"
     ]
    }
   ],
   "source": [
    "# init CE Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# sequence of length 1\n",
    "output = torch.rand(1, 5)\n",
    "# in this case the 1th class is our target, index of 1th class is 0\n",
    "target = torch.LongTensor([0])\n",
    "loss = criterion(output, target)\n",
    "print('Sequence of length 1:')\n",
    "print('Output:', output, 'shape:', output.shape)\n",
    "print('Target:', target, 'shape:', target.shape)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
